# Visionary

**Visionary** is a smart digital tool empowering visually impaired individuals with real-time computer vision capabilities for enhanced situational awareness and accessibility.

---

## What It Does

Visionary integrates a suite of features to assist users by:

- Detecting surrounding objects  
- Recognizing familiar faces  
- Transcribing on-scene text (OCR + TTS)  
- Providing distance feedback for safer navigation  
- Enabling intuitive usage through gesture controls (shake to sync contacts, hold to initiate detection)

Learn more about the project and its impact on the Devpost submission.:contentReference[oaicite:0]{index=0}

---

## Tech Stack

The app was built using:

- **Swift** (iOS development)  
- **Computer Vision frameworks**: YOLO (object detection), FaceNet or OpenCV (face recognition), OCR  
- **Text-to-speech**: Apple’s SpeakText (for vocalizing detected text)  
- **LiDAR APIs** (e.g., available on iPhone devices) for real-time distance sensing  
- **Gesture-based interaction** for a non-visual control flow (shake/hold)

*(These details are drawn from the Devpost summary and technical overview.)*:contentReference[oaicite:1]{index=1}

---

## Explore & Try It Out

- **Live Demo / Website**: [Visionary Live Site](https://visionarywebsite-self.vercel.app/)  
- **Project Details & Submission**: [Visionary on Devpost](https://devpost.com/software/visionary-9rixy3)

---

**Visionary** aims to bridge gaps in mobility and independence using accessible tech—making everyday journeys safer and more intuitive for visually impaired users.

